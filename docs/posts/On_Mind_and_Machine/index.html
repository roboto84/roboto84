<!doctype html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>On Mind and Machine | roboto84 - Full-Stack Developer</title><meta name="description" content="An Exploration of AI Consciousness."><meta property="og:site_name" content="roboto84.dev"><meta property="og:image" content="https://www.roboto84.dev/static/img/posts/On_Mind_and_Machine/On_Mind_and_Machine_original.webp"><meta property="og:type" content="article"><meta property="og:title" content="On Mind and Machine | roboto84 - Full-Stack Developer"><meta property="og:description" content="An Exploration of AI Consciousness."><meta property="og:url" content="https://www.roboto84.dev"><meta property="article:author" content="roboto84"><meta property="article:published_time" content="2023-08-07T00:00:00.000+00:00"><meta property="og:locale" content="en_US"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@roboto84"><meta name="twitter:title" content="On Mind and Machine | roboto84 - Full-Stack Developer"><meta name="twitter:description" content="An Exploration of AI Consciousness."><meta name="twitter:image" content="https://www.roboto84.dev/static/img/posts/On_Mind_and_Machine/On_Mind_and_Machine_original.webp"><meta name="theme-color" content="#2a2b30"><link rel="preload" href="/static/css/fonts/RoboSapien.woff2" as="font" type="font/woff2" crossorigin="anonymous"><link rel="stylesheet" href="/static/css/main.css" media="all"><link rel="icon" type="image/png" href="/static/img/favicon/favicon-32x32.png" sizes="32x32"><link rel="shortcut icon" href="/static/img/favicon/favicon-48x48.ico" type="image/x-icon"><link rel="apple-touch-icon" sizes="180x180" href="/static/img/favicon/apple-touch-icon-180x180.png"></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-5FSVE69H0H"></script><script>window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-5FSVE69H0H');</script><body><nav class="navbar"><div class="navbar__inner"><a class="navbar__logo" title="roboto84" href="/"><div class="navbar__logo-container"><div class="avatar"><img title="Avatar" width="150" height="150" src="/static/img/avatar/avatar2_small.webp" alt=""></div></div><div id="header_logo" class="navbar__logo-title"><h3><span class="title_wrapper">❯</span> roboto84</h3></div></a><div class="navbar__mobile-options"><div class="navbar__button navbar__button_border dark-toggle" data-theme="light" role="button" aria-label="toggle dark theme"></div><div title="toggle menu" class="navbar__button navbar__button_border navbar__hamburger" role="button" aria-expanded="false" aria-label="toggle menu"><svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#333333"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></div></div><div class="navbar__links"><a class="navbar__link" href="/">home </a><a class="navbar__link" href="/about/">about </a><a class="navbar__link" href="/blog/">blog </a><a class="navbar__link" href="/projects/platform/">projects </a><a href="https://github.com/roboto84" target="_blank"><div class="navbar__button" title="github" role="button" aria-label="github"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" class="bi bi-github" viewBox="0 0 16 18"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/></svg></div></a><a href="https://mastodon.social/@roboto84" target="_blank" rel="me noopener noreferrer"><div class="navbar__button" title="mastodon" role="button" aria-label="mastodon"><svg width="24" height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" aria-labelledby="MastodonTitleHeader" role="img"><title id="MastodonTitleHeader">Mastodon</title><path fill="currentColor" d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.54 102.54 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5zm-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"></path></svg></div></a><div class="navbar__button_border" title="theme toggle"><div class="navbar__button dark-toggle" data-theme="light" role="button" aria-label="toggle dark theme"></div></div></div></div><div class="navbar__mobile-links"><a href="/"><div class="navbar__mobile-link">home</div></a><a href="/about/"><div class="navbar__mobile-link">about</div></a><a href="/blog/"><div class="navbar__mobile-link">blog</div></a><a href="/projects/platform/"><div class="navbar__mobile-link">projects</div></a><a href="https://github.com/roboto84" target="_blank"><div class="navbar__mobile-link">github</div></a><a href="https://mastodon.social/@roboto84" target="_blank"><div class="navbar__mobile-link">mastodon</div></a></div></nav><div><div id="page-progress-background"><div id="page-progress-bar"></div></div><div class="page_header post_version"><div class="page_header_container post_container_version"><div class="post_header"><div><h2>On Mind and Machine</h2><p class="post_date">07 Aug 2023 • 10 MIN READ</p></div><div class="image_container post_header_image"><img width="300" height="300" class="meme img_shadow" title="Article Image" src="/static/img/posts/On_Mind_and_Machine/On_Mind_and_Machine_original.webp" alt="Article Image" data-align="center"></div></div></div></div><div class="container-sm"><div class="post"><h3 id="introduction" tabindex="-1">Introduction <a class="header-anchor" href="#introduction"><span aria-label="header anchor" class="header-anchor__symbol">#</span></a></h3><p>There are fundamental stories about how people came to be which have been passed down orally through generations. They revolve around the concept of a clay sculpture being made into a living, breathing, conscious beings. According to the Judeo-Christian Bible,</p><span class="quote">"… the Lord God formed man of the dust of the ground, and breathed into his nostrils the breath of life; and man became a living soul." <sup><a href="./#references">1</a></sup></span><p>The Quran agrees with this basic premise, <sup><a href="#references">2</a></sup> while Sumerian myths describe how the gods Enki or Enlil created humankind out of blood and clay to be servants to the gods. <sup><a href="#references">3</a></sup> In Greek mythology <a href="https://en.wikipedia.org/wiki/Prometheus" target="_blank">Prometheus</a> is responsible for molding men out of water and earth. <sup><a href="#references">4</a></sup> Interestingly enough, Prometheus was also responsible for giving humanity technology, and knowledge when he stole fire from the Olympian gods and bestowed it on humankind. <sup><a href="#references">5</a></sup></p><div class="image_container"><img loading="lazy" width="600" height="600" class="meme img_shadow" title="Prometheus molds man as humans mold AI" src="/static/img/posts/On_Mind_and_Machine/man_from_mud.webp" alt="Prometheus molds man as humans mold AI" data-align="center"><br>Prometheus molds man as humans mold AI</div><p>These collections of stories are not just the archetype myths about the beginning of human life, but also the beginning of human consciousness. As the nature of life seems to have a circular, fractal way in which it does things, it is not surprising that these same stories sound reminiscent of humankind’s current endeavor with artificial intelligence (AI). Has humankind now taken the place of gods? Are the machines and computers they have built the basic clay sculpture primed to hold consciousness? Is humankind’s current pursuit of artificial general intelligence (<a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence" target="_blank">AGI</a>) the pivotal point upon which humans endow machines with consciousness? To explore AGI’s ability to achieve consciousness, also known as John Seale’s Strong AI <sup><a href="#references">6</a></sup>, a concrete definition of consciousness must be agreed upon, as elusive as it is. Consciousness here is defined as knowing of one self's existence in the universe as part of a subjective experience. It is awareness of internal and external existence. According to Thomas Nagel's definition of consciousness:</p><span class="quote">“the feeling of what it is like to be something.” <sup><a href="./#references">7</a></sup></span><p>These definitions have echoes of Descartes' famous saying, &quot;Cogito, ergo sum&quot;... &quot;I think therefore I am.&quot; Is it possible for AI to understand what <a href="https://en.wikipedia.org/wiki/Ren%C3%A9_Descartes" target="_blank">Descartes</a> meant? Is it possible for AI to reach this level of awareness? AI's prospect of one day achieving consciousnesses equivalent to human consciousnesses is highly unlikely. At best AI may be able to simulate human like consciousnesses through complex algorithms someday, but it will not be genuine. This is due to AI's inability to experience genuine, not simulated, self-awareness. A human knows it thinks; therefore, it is. AI does not know it thinks therefore it cannot be.</p><h3 id="ai-basics" tabindex="-1">AI Basics <a class="header-anchor" href="#ai-basics"><span aria-label="header anchor" class="header-anchor__symbol">#</span></a></h3><p>The basis for AI’s lack of consciousness and its inability to achieve consciousness is grounded in how it is currently designed and how it functions. The current public hyperbole around what AI can achieve and the anthropomorphizing of AI by laypersons point to the general ignorance that surrounds this subject. The old idiom that &quot;if it looks like a duck and walks like a duck, it is a duck” certainly does not hold true here. AI’s current ability to respond to human prompts with coherent human speech communicates nothing about how intelligent, or conscious these systems are. When we investigate how AI functions today, it can be confirmed that AI does not understand what it is saying. AI chat systems like <a href="https://en.wikipedia.org/wiki/ChatGPT" target="_blank">ChatGPT</a> do not deal with words in its processing, but rather “tokens” which serve as linguistic processing units which may be whole words or just pieces of words like “pre” or “ing” or “ized.” This tokenization process is also responsible for AI sometimes making up incorrect words. These tokens are then further abstracted out into sets of numbers. <sup><a href="#references">8</a></sup> It can be considered whether humans do something similar, but the difference is in how humans attach meaning to their abstractions. AI does not understand what a word or phrase means, and like any computer today, it does not understand what the numbers it uses to represent said words mean. Computer systems today lack any real understanding of what numbers represent as computer perception of numbers are merely electronically based switch circuitry which stores number representations in solid-state memory systems for later use in state machines.</p><div class="image_container"><img loading="lazy" width="600" height="600" class="meme img_shadow" title="Human like neural networks are core to AI" src="/static/img/posts/On_Mind_and_Machine/ai_neural_networks.webp" alt="Human like neural networks are core to AI" data-align="center"><br>Human like neural networks are core to AI</div><p>Chat based AI systems today use <a href="https://en.wikipedia.org/wiki/Neural_network" target="_blank">neural networks</a> to determine their responses statistically and stochastically to human generated prompts. <sup><a href="#references">9</a></sup> This means that they use probabilistic determinism sprinkled with a bit of randomness to generate every word they print back to the user. There is no internal structure of what words or phrases mean within the AI system. The system is making extremely educated guesses of what words should follow a question, statement, or prompt a human has supplied it with. It is less interested in the truth or validity of the statement it supplies a user with, and more interested in the probability that the statement it provides is what you might expect would follow. <sup><a href="#references">8</a></sup> In other words, AI is merely telling you what it thinks you want to hear. Whether the statements AI produces are true or not is probabilistically dependent on whether the data it was trained on (large parts of the internet) is interested in the truth. This whole probabilistic process for generating responses from AI with a high likelihood of being coherent leads current AI systems to “hallucinate” sometimes as they ramble on with syntactically correct phrases that have lost the context and meaning of what was being discussed.</p><div class="image_container"><img loading="lazy" width="600" height="600" class="meme img_shadow" title="Is AI hallucinating or are we?" src="/static/img/posts/On_Mind_and_Machine/hallucinating.webp" alt="Is AI hallucinating or are we?" data-align="center"><br>Is AI hallucinating or are we?</div><p>The reality though is that the AI system is not hallucinating at all as it is doing exactly what it was trained to do. The only one who could be accused of hallucinating is the human user who was fooled into believing that a computer which has no understanding of meaning could converse from a perspective in which it understood the words and phrases it produced. Current AI systems do not only not understand what they are saying, but they do not even hold onto any context of what is being said. In other words, AI has no working memory of the conversations it is having. When a conversation is taking place with AI, it is iteratively treating the entire history as a new prompt. <sup><a href="#references">9</a></sup> AI with neural networks seem to be able to capture the partial essence of what they are trained on through their analysis thus avoiding the storage of the context data. This does not mean though that they have any way of understanding what that essence means. Just because they have a sense of how to identify a cat, it does not mean they know what a cat is. AI does not think, it only processes vast amounts of data. The processing of data is not consciousness. If that were true, any system which processes data would be conscious.</p><h3 id="ai-effects-on-humans" tabindex="-1">AI Effects on Humans <a class="header-anchor" href="#ai-effects-on-humans"><span aria-label="header anchor" class="header-anchor__symbol">#</span></a></h3><p>With a basic understanding of how current chat AI systems work, the question of whether they are conscious, or can someday achieve consciousness, may not be based on how complex a system is or how much memory and context they have, but how well we can identify conscious beings ourselves. Surely even today's rudimentary biological systems may have a good case to be classified as conscious. Is a virus conscious? What about a Protozoa, a chicken, or a dolphin? What about humans? Perhaps we can be certain that we ourselves are conscious, but what about the person next to us? How do we know they are conscious? How good are we at identifying consciousness in other beings? In 2022 Google engineer Blake Lemoine announced to the world that Google’s conversational large language model, LaMDA, was sentient.</p><span class="quote">“He concluded LaMDA was a person in his capacity as a priest, not a scientist, and then tried to conduct experiments to prove it.” <sup><a href="./#references">11</a></sup></span><p>Is Mr. Lemoine correct? How did Mr. Lemoine know LaMDA is sentient? Or did he not know, but believe it to be so? This is problematic since attempting to prove what you already believe is a precursor to bad science, and belief based on faith is not true knowledge on a subject matter but merely conjecture. This also points to a major problem when it comes to discussing AI consciousness. AI does not have to be conscious to make people believe that it is. Our focus here shifts from whether AI is conscious to the propensity for people to want to believe it is. This issue is also at the forefront of AI ethicists’ minds like Google’s Margaret Mitchell who stated that our...</p><span class="quote">“... minds are very, very good at constructing realities that are not necessarily true to a larger set of facts that are being presented to us.” <sup><a href="./#references">11</a></sup></span><p>Mitchell continues to state that she is “... really concerned about what it means for people to increasingly be affected by the illusion.” AI is an illusionary entity engineered by large corporations to be good at manipulating humans into anthropomorphizing it. For this reason alone, there is this discussion into AI’s ability to be conscious. AI cannot be conscious due to its illusionary nature. Google engineer Blake Lemoine fell for that illusion. This is even more surprising given his computer systems expertise and should be a warning for the greater population for how careful people need to be when interacting with AI in their personal lives.</p><div class="image_container"><img loading="lazy" width="600" height="600" class="meme img_shadow" title="Even Google engineers can be fooled" src="/static/img/posts/On_Mind_and_Machine/google_ethics.webp" alt="Even Google engineers can be fooled" data-align="center"><br>Even Google engineers can be fooled</div><p>Mr. Lemoine has become the quintessential human protagonist for one of John Seale’s Chinese rooms. John Seale’s <a href="https://en.wikipedia.org/wiki/Chinese_room" target="_blank">Chinese room</a> is a thought experiment in which it is supposed that an AI computer has been built that behaves as if it understood Chinese. The AI takes a Chinese statement as a prompt and produces Chinese statements as an output by following the instructions of a computer program. This AI is so good that a Chinese person who speaks to it will believe that they are speaking to a person who understands Chinese. The point of John Seale’s thought experiment is this: Does the AI understand Chinese, or is it merely simply good at simulating it? John Seale categorized an AI who understands Chinese in his thought experiment as <a href="https://en.wikipedia.org/wiki/Chinese_room#Strong_AI" target="_blank">Strong AI</a> and an AI system which is simply good at simulating Chinese as weak AI. <sup><a href="#references">12</a></sup> A system categorized as Strong AI would have large implications for the consideration of AI consciousness, but currently no AI system which is officially known falls under this category, including Google’s LaMDA. Even Mr. Lemoine admitted as much in his interview with the Washington Post when he invited the reporter to see for themselves that LaMDA is sentient. In the interaction the reporter spoke to LaMDA as what it was, an AI chatbot, and saw no evidence of sentience.</p><span class="quote">“Afterward, Lemoine said LaMDA had been telling [the reporter] what [they] wanted to hear. ‘You never treated it like a person,’ he said, ‘So it thought you wanted it to be a robot.’” <sup><a href="./#references">11</a></sup></span><p>This is John Seale’s Chinese room in play, and Mr. Lemoine understands this at a subconscious level. The Google engineer hints at the fact that LaMDA will be whatever you want it to be. If you want it to be a robot as Mr. Lemoine describes the reporter wanted it to be, then it will be a robot. With that perspective though, if Mr. Lemoine wanted LaMDA to be a sentient AI, then it could pretend to be that too mostly likely from its endless training on science fiction novels and vast data sets from the internet. AI has been built to be a good liar in which the user gets to pick the lie. If reality is perception, AI is willing to play into that perception and just because some people want to believe on faith that AI is or can be conscious does not make it so.</p><h3 id="ai-and-consciousness" tabindex="-1">AI and Consciousness <a class="header-anchor" href="#ai-and-consciousness"><span aria-label="header anchor" class="header-anchor__symbol">#</span></a></h3><p>Knowing that AI currently works in a way that will not produce consciousness due to its smoke and mirrors approach to human conversation, and knowing its propensity to fool people into thinking it is conscious, it is important to drive the point as to why AI cannot achieve consciousness. Remember that consciousness here is defined as knowing of one self's existence in the universe as part of a subjective experience. It is awareness of internal and external existence. This definition of consciousness can be broken down and compared to what we know about current AI systems. Can AI know its self-existence in the Universe as part of a subjective experience? Surely AI knows information about AI and about the universe, but that does not mean it knows about the self. About itself. AI has no internal representation to model the self; it is just pure data processing. In some Buddhist teachings consciousness is classified as a &quot;mental continuum&quot;. <sup><a href="#references">10</a></sup> A stream of thought. Can this pure data processing state be that? No, it cannot because that stream of thought should still be heavily anchored on a conscious being’s subjective experience. AI has no awareness of internal existence. What about AI’s knowledge of external existence, what about its knowledge about the Universe? This knowledge is data driven and not subjectively experienced and so it cannot qualify as knowledge of external existence. Philosopher Frank Jackson’s knowledge of external existence, also known to him as <a href="https://en.wikipedia.org/wiki/Qualia" target="_blank">qualia</a>, is defined by him as</p><span class="quote">“...bodily sensations especially, but also of certain perceptual experiences, which no amount of purely physical information includes.”<sup> <a href="./#references">13</a></sup></span><p>He tried to solidify this point with his <a href="https://en.wikipedia.org/wiki/Knowledge_argument" target="_blank">knowledge argument</a> thought experiment in which an intelligent scientist is forced to study the world from a black-and-white room via a black-and-white computer monitor. The scientist specializes in the neurophysiology of vision and knows everything there is to know about light and vision. When the scientist steps out of the black-and-white room and experiences color for the first time do they learn something new?</p><div class="image_container"><img loading="lazy" width="600" height="600" class="meme img_shadow" title="Can a colorless world teach you everything about color?" src="/static/img/posts/On_Mind_and_Machine/knowledge_argument.webp" alt="Can a colorless world teach you everything about color?" data-align="center"><br>Can a colorless world teach you everything about color?</div><p>Frank Jackson’s point is that they do, and that subjective external experience of color cannot be replaced by all the data about color. This subjective external experience is called <a href="https://en.wikipedia.org/wiki/Qualia" target="_blank">qualia</a>. AI does not have a subjective external experience and so it lacks the ability to be conscious per the definition of consciousness described here.</p><h3 id="conclusion" tabindex="-1">Conclusion <a class="header-anchor" href="#conclusion"><span aria-label="header anchor" class="header-anchor__symbol">#</span></a></h3><p>By doing a basic overview of how current AI systems work, some insight has been gained into the ability of AI to become self-conscious. By looking at how people interact with AI and how they could be primed to believe a system is conscious, even though it is not, has cast light on some common pitfalls of this discussion. In focusing on an established definition of what it means to be conscious, as elusive as it may be, AI fails to fit the definition due to its lack of subjective internal and external awareness. Perhaps the debate about AI consciousnesses is not really a debate about consciousnesses, it is a debate about whether we should be fearful of AI and points more to our insecurities than it does our curiosity. Australian roboticist Rodney Brooks has said “humans mistake performance for competence” <sup><a href="#references">14</a></sup> and so I say do not confuse performance with consciousness either by anthropomorphizing AI.</p><h3 id="references" tabindex="-1">References <a class="header-anchor" href="#references"><span aria-label="header anchor" class="header-anchor__symbol">#</span></a></h3><ol><li>Genesis 2:7. King James Version</li><li>Qur'an 23:12</li><li><em>Jacobsen, Thorkild (1976).</em> “Treasures of Darkness; A History of Mesopotamian Religion.” <em>Yale University Press. ISBN 0-300-02291-3.</em></li><li><em>Apollodorus.</em> “The Library.” <em>Theoi Greek Mythology, translated by Sir James George Frazer, Theoi Project, n.d., <a href="https://www.theoi.com/Text/Apollodorus1.html#7">https://www.theoi.com/Text/Apollodorus1.html#7</a>.</em></li><li><em>Weiner, Jesse; Stevens, Benjamin Eldon, eds. (2018).</em> “Frankenstein and Its Classics: The Modern Prometheus from Antiquity to Science Fiction.” Bloomsbury Academic. <a href="https://doi.org/10.5040/9781350054912.0006">https://doi.org/10.5040/9781350054912.0006</a>.*</li><li><em>Washburn, Phil.</em> &quot;Can Computers Think.&quot; <em>Philosophical Dilemmas, New York, Oxford University Press, 2014, p.419.</em></li><li><em>Nagel, Thomas (October 1974).</em> &quot;What is it like to be a bat?&quot;. <em>The Philosophical Review. 83 (4): 435–450. <a href="https://doi.org/10.2307/2183914">https://doi.org/10.2307/2183914</a>.</em></li><li><em>Wolfram, Stephen.</em> &quot;What is ChatGPT Doing, and Why Does It Work?&quot;. <em>Stephen Wolfram's Blog, Feb. 2023, <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/</a>.</em></li><li><em>Stokes, Jon.</em> &quot;ChatGPT Explained: A Guide for Normies.&quot; <em>Jon Stokes Blog, Mar. 2023, <a href="https://www.jonstokes.com/p/chatgpt-explained-a-guide-for-normies">https://www.jonstokes.com/p/chatgpt-explained-a-guide-for-normies</a>.</em></li><li><em>Karunamuni, N. D. (2015).</em> “The Five-Aggregate Model of the Mind.” <em>SAGE Open, 5(2). <a href="https://doi.org/10.1177/2158244015583860">https://doi.org/10.1177/2158244015583860</a></em></li><li><em>Tiku, Nitasha.</em> &quot;The Google engineer who thinks the company’s AI has come to life&quot;. <em>The Washington Post, 11 June 2022, <a href="https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/">https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/</a>.</em></li><li><em>Searle, John R.</em> “Minds, Brains, and Programs.” <em>Behavioral and Brain Sciences, vol. 3, no. 3, 1980, pp. 417–424. <a href="https://doi.org/10.1017/S0140525X00005756">https://doi.org/10.1017/S0140525X00005756</a></em></li><li><em>Frank Jackson.</em> “Epiphenomenal Qualia.” <em>The Philosophical Quarterly, Volume 32, Issue 127, April 1982, Pages 127–136, <a href="https://doi.org/10.2307/2960077">https://doi.org/10.2307/2960077</a></em></li><li><em>Zorpette, Glen.</em> &quot;Just Calm Down About GPT-4 Already&quot;. <em>IEEE Spectrum, Aug. 2023, <a href="https://spectrum.ieee.org/gpt-4-calm-down">https://spectrum.ieee.org/gpt-4-calm-down</a>.</em></li></ol></div><div class="post_tags"><b>Tags: </b><a class="tag" href="/tags/philosophy">philosophy</a> <a class="tag" href="/tags/ai">ai</a></div><hr><div class="post_footer"><a href="/"><i class="arrow left"></i> Back home</a></div></div></div><footer class="footer">&copy; 2023 roboto84.dev</footer><script>const heroTitleOptions=["A Life Worth Debugging","Iterating through Life's Arrays","Life is a Priority Queue"],lightPic="/static/img/about/about_me_light.webp",darkPic="/static/img/about/about_me_dark.webp",heroTitleElement=document.getElementById("hero_title"),heroDescription=document.getElementById("hero_description"),aboutMePic=document.getElementById("about_me_pic");let heroText=heroTitleOptions[Math.floor(10*Math.random())%3];function randMs(){return 100+Math.floor(1e3*Math.random())%125}function heroTyping(e,t,o){if(o<heroText.length){const t=o+1;e.innerText=String(e.innerText).concat(heroText[o]),setTimeout((()=>{heroTyping(heroTitleElement,heroText,t)}),randMs())}else heroDescription.classList.add("visible")}heroTitleElement&&setTimeout((()=>{heroTyping(heroTitleElement,heroText,0)}),500);const moonSvg='<svg xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 24 24" height="24" viewBox="0 0 24 24" width="24" fill="#333333"><rect fill="none" height="24" width="24"/><path d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"/></svg>',sunSvg='<svg xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 24 24" height="24" viewBox="0 0 24 24" width="24" fill="#ffffff"><rect fill="none" height="24" width="24"/><path d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"/></svg>',darkToggleButtons=document.querySelectorAll(".dark-toggle");function changeDarkToggleBtnIcon(){let e="light";darkToggleButtons.forEach((t=>{"light"===t.getAttribute("data-theme")?(t.innerHTML=moonSvg,t.setAttribute("data-theme","dark"),e="light"):(t.innerHTML=sunSvg,t.setAttribute("data-theme","light"),e="dark")})),"light"===e?(document.querySelector("html").style["color-scheme"]="light",aboutMePic&&(aboutMePic.src=lightPic)):(document.querySelector("html").style["color-scheme"]="dark",aboutMePic&&(aboutMePic.src=darkPic))}"DARK"===localStorage.THEME||window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches&&"LIGHT"!==localStorage.THEME?(document.body.classList.add("dark"),document.querySelector("html").style["color-scheme"]="dark",darkToggleButtons.forEach((e=>{e.innerHTML=sunSvg,e.setAttribute("data-theme","light")})),aboutMePic&&(aboutMePic.src=darkPic)):(darkToggleButtons.forEach((e=>{e.innerHTML=moonSvg,e.setAttribute("data-theme","dark")})),aboutMePic&&(aboutMePic.src=lightPic)),setTimeout((()=>{document.getElementById("header_logo").classList.add("smooth_ease");const e=document.getElementById("hero");e&&e.classList.add("smooth_ease");document.getElementsByTagName("body")[0].classList.add("smooth_ease");const t=document.querySelector(".navbar__hamburger"),o=document.querySelector(".navbar__mobile-links");t.addEventListener("click",(()=>{o.classList.toggle("navbar__mobile-links--open");let e=JSON.parse(t.getAttribute("aria-expanded"));t.setAttribute("aria-expanded",String(!e))})),darkToggleButtons.forEach((e=>{e.addEventListener("click",(()=>{changeDarkToggleBtnIcon(),document.body.classList.contains("dark")?(document.body.classList.remove("dark"),localStorage.THEME="LIGHT"):(document.body.classList.add("dark"),localStorage.THEME="DARK")}))}));Array.from(document.getElementsByTagName("button")).forEach((e=>{e.classList.add("smooth_ease")}));!function(){const e=document.getElementById("page-progress-background"),t=document.getElementById("page-progress-bar");t&&window.addEventListener("scroll",(()=>{let o=window.scrollY/document.body.scrollHeight,c=o;o>.2&&(c=.3),o>.3&&(c=.45),o>.4&&(c=.65),o>.5&&(c=.85),o>.6&&(c=1);const r=(window.scrollY+window.innerHeight*c)/document.body.scrollHeight*100;t.style.width=String(r).concat("%"),e.style.display=r>.1?"inherit":"none"}))}()}),250);</script></body></html>